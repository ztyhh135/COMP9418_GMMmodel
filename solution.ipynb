{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 (Part 2)\n",
    "** COMP9418 - Advanced Topics in Statistical Machine Learning **\n",
    "\n",
    "** Instructor: Edwin V. Bonilla **\n",
    "\n",
    "** Last update: August 23rd at 10:35pm **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "In this practical part of the assignment you will build a class-conditional classifer using Gaussian Mixture Models (GMMs). \n",
    "\n",
    "1. For all the machine-learning related code you have two options: (a) use [scikit-learn](http://scikit-learn.org/stable/) and/or (b) write your own code. In particular, for fitting GMMs or building the classifier, you should refrain from using other packages. \n",
    "2. You can use the same GMM package that we used in the corresponding tutorial on GMMs, i.e. [scikit-learn Gaussian Mixture](http://scikit-learn.org/stable/modules/mixture.html). You should use standard (non-variational) Expectation-Maximisation updates  for parameter estimation. \n",
    "3. Do not delete any of the existing code in this notebook as we will use it to assess the performance of your algorithm.\n",
    "\n",
    "### Main task\n",
    "Your tasks is to build a class-conditional classifier for classifying digits using the MNIST dataset. You are given a file `mnist_train.npz` that contains images of digits (0-9). \n",
    "- The features `xtrain`, which have been normalized to be between [0,1], are 784 dimensional vectors corresponding to 28 * 28 image intensities. \n",
    "- The targets `ytrain` contain the class label of each example using one-hot-encoding. \n",
    "- In total there are 60,000 examples, each with one label from the 10 different classes. \n",
    "- The original dataset can be found at http://yann.lecun.com/exdb/mnist/ and you can read more about this dataset there. However, this dataset has been processed and shuffled so the training and test data in this exercise do not correspond to the original sets. \n",
    "- Note that you are only provided with training data `xtrain`, `ytrain`. In order to learn and test you model, you may consider splitting these data into training, validation and testing.   In particular, if you want to assess the performance of your model in section 2, you must create a test set `mnist_test.npz`. You are not required to submit this test file as we will evaluate the performance of your model using our own test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher\n",
    "Recall that a class-conditional classifier models the joint distribution of features $\\mathbf{x}$ and classes $y$ as $p(\\mathbf{x}, y) = p(y) p(\\mathbf{x} | y)$ and then uses Bayes' rule $p(y | \\mathbf{x}) \\propto  p(y) p(\\mathbf{x} | y)$ to make predictions. In this assignment, you will use a GMM for each of the conditional densities $p(\\mathbf{x} | y)$ and a Categorical distribution for $p(y)$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment\n",
    "Your work will be assessed based on:\n",
    "- [50%] the application of the concepts for doing model selection, which allows you to learn a single model for prediction (Section 1);  \n",
    "- [30%] the code you write for making predicitions in your model (Section 2); and\n",
    "- [20%] the predictive performance of your model (Section 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages \n",
    "Add required libraries here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sklearn as skl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Put the graphs where we can see them\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function below to plot a digit in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_image(array, dim=28):\n",
    "    \"\"\"\n",
    "    Plot array as an image of dimensions dim * dim\n",
    "    \"\"\"\n",
    "    img = array.reshape(dim,dim, order = \"C\")\n",
    "    pl.imshow(img, cmap=pl.cm.gray)\n",
    "    ax = pl.gca();ax.set_yticks([]);ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you should load your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('mnist_train.npz')\n",
    "\n",
    "# training data\n",
    "xtrain = data['xtrain']\n",
    "ytrain = data['ytrain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here and example of plotting a specific digit and showing its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwIJFwIJFwL9F1rvFqkWhbDJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9ad2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 10\n",
    "plot_image(xtrain[idx,:])\n",
    "print ytrain[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [50%] Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place all the code for training your model using the function `train_model` below. \n",
    "\n",
    "- We should be able to run your notebook (by clicking 'Cell->Run All') without errors. However, you must save the trained model in the file `model.npz`. This file will be loaded to make predictions in section 2 and assess the performance of your model in section 3. Note that, in addition to this notebook file, <span style=\"color:red\"> ** you must provide the file model.npz **</span>.\n",
    "\n",
    "- You should comment your code as much as possible so we understand your reasoning about training, model selection and avoiding overfitting. \n",
    "\n",
    "- You can process the data as you wish, e.g. by applying some additonal transformations, reducing dimensionality, etc. However, all these should be here too. \n",
    "- Wrap all your training using the function `train_model` below. You can call all other custom functions within it.\n",
    "\n",
    "- I strongly discourage you from using a full covariance for each of the components of your Gaussian mixture, as the number of parameters grows quadratically on the dimensionality of the data and you will be unable to fit the file size cap in your submission (besides running into various numerical issues). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(xtrain, ytrain):\n",
    "    \"\"\"\n",
    "    Write your code here.\n",
    "    \"\"\"\n",
    "    # reduce train set to 20 dimensions with pca\n",
    "    pca = PCA(n_components=20)\n",
    "    pca.fit(xtrain)\n",
    "    xtrain_fix = pca.transform(xtrain)\n",
    "    \n",
    "    # change ytrain from one-hot type to Numeric, they will helpfull in next step\n",
    "    ytrain_fix = np.zeros(ytrain.shape[0])\n",
    "    for i,x in enumerate(ytrain):\n",
    "        n=0\n",
    "        while n<10:\n",
    "            if ytrain[i,n]==1:\n",
    "                ytrain_fix[i]=n\n",
    "                break\n",
    "            n+=1\n",
    "            \n",
    "    # save class label and number of samples in each\n",
    "    subtrain = []\n",
    "    length = []\n",
    "    for i in range(10):\n",
    "        subtrain.append((ytrain_fix==i).ravel())\n",
    "        length.append(xtrain_fix[subtrain[i]].shape[0])\n",
    "        \n",
    "    # create the model set, using 10*10 models with 10 for each class\n",
    "    gmm = []\n",
    "    for i in range(10):\n",
    "        subgmms=[]\n",
    "        for j in range(10):\n",
    "            subgmm = mixture.GaussianMixture(\n",
    "                        n_components=j+1,\n",
    "                covariance_type='full')\n",
    "            subgmm.fit(xtrain_fix[subtrain[i], :])\n",
    "            subgmms.append(subgmm)\n",
    "        gmm.append(subgmms)\n",
    "    #save gmms and pca to model\n",
    "    model = []\n",
    "    model.append(gmm)\n",
    "    model.append(pca)\n",
    "    model.append(length)\n",
    "    # You can modify this to save other variables, etc \n",
    "    # but make sure the name of the file is 'model.npz.\n",
    "    np.savez_compressed(\n",
    "        'model.npz',\n",
    "        model=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [30%] Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will assume that there is a file `mnist_test.npz` from which we will load the test data.  As this file is not given to you, you will need to create one yourself (but not to submit it) to test your code. <span style=\"color:red\">Note that if you do not create this file the cell below will not run</span>. \n",
    "\n",
    "Your task is to fill in the `make_predictions` function below. Note that this function should load your `model.npz` file, which must contain all the data structures necessary for making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABLpJREFUeJzt3VFS40YUQFEpxT6yFPDKgJUBS8n/7EHZQFDbaWT7mnN+\nJXlkJ7d6qt60tG7btgAtf936BoDLCReChAtBwoUg4UKQcCFIuBAkXAgSLgQ9XXLyuq7+mRUcbNu2\ndXSOFReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKF\nIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIejp1jfA\nffv4+Pj22MvLy+617+/vu8ff3t7+xx2xLFZcSBIuBAkXgoQLQcKFIOFCkHAhyBw3bm/OuizjWeuR\nXl9fp6435/2eFReChAtBwoUg4UKQcCFIuBBkHHTntm279S0c5vn5eff43ijr8/PzZ28mxooLQcKF\nIOFCkHAhSLgQJFwIEi4EmeNewWh72sz2t9E88+vra+r60bbBGaMth3v3bo4L5AgXgoQLQcKFIOFC\nkHAhSLgQZI77A0bzyNG+0xmjV1nOzjv3rj/60a9H/m51VlwIEi4ECReChAtBwoUg4UKQcCHIHPcH\nHLlndV3Xwz77HHt7Yo+e445m1L+ZFReChAtBwoUg4UKQcCFIuBAkXAgyxz3D6LnIs+55XjnzzOdZ\n3o/7PSsuBAkXgoQLQcKFIOFCkHAhaN227fyT1/X8k0NG29Nmt+2NRhen02nq82eMvvveOGh036Pf\nbWZb4K23Ox5p27bhl7PiQpBwIUi4ECRcCBIuBAkXgoQLQbb1Lcc/ZnTvEae3Npoxz2yfG21XPPp3\nf2RWXAgSLgQJF4KEC0HChSDhQpBwIcgc9wp+66NEZ2fEe3Pe0SNzj36k7q1ZcSFIuBAkXAgSLgQJ\nF4KEC0HChSBz3Cv4rXPckdE+5b057uj1n+a4wN0RLgQJF4KEC0HChSDhQpBwIcgcl6TfPhu34kKQ\ncCFIuBAkXAgSLgQJF4KMg0i651eXXoMVF4KEC0HChSDhQpBwIUi4ECRcCDLH5WZGj1jdY1sfkCNc\nCBIuBAkXgoQLQcKFIOFCkDnuMp4Jzswbl2X8ysdHfSXkx8fH1PV7/13McYEc4UKQcCFIuBAkXAgS\nLgQJF4LWbdvOP3ldzz/5gYzmkS8vL1Ofv67r1PW3Mvres3Pc0+n07bFHnuNu2zb8H8KKC0HChSDh\nQpBwIUi4ECRcCLKt7wzv7++7x2fHQXtjk72RyDXs3dvs9x79ro888pllxYUg4UKQcCFIuBAkXAgS\nLgQJF4Js6/sBl/yGlxrNMr++vqY+f/bRs3tGM2hz2v9mWx88KOFCkHAhSLgQJFwIEi4ECReCzHF/\nwNGPKb2lvVnrrfcKPypzXHhQwoUg4UKQcCFIuBAkXAgSLgSZ417BaM67d3x2v+zsft63t7epP5/L\nmePCgxIuBAkXgoQLQcKFIOFCkHAhyBwX7ow5Ljwo4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBw\nIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4EPV14/p9lWf454kaAZVmW5e9zTrroucrA\nffBXZQgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCPoXmX7hRVrVmyAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4782668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = np.load('mnist_test.npz')\n",
    "# test data\n",
    "xtest = test['xtest']\n",
    "ytest = test['ytest']\n",
    "idx = 1000\n",
    "plot_image(xtest[idx,:])\n",
    "print ytest[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(xtest):\n",
    "    \"\"\"\n",
    "    @param xtest: (Ntest,D)-array with test data\n",
    "    @return class_pred: (N,C)-array with predicted classes using one-hot-encoding \n",
    "    @return class_logprob: (N,C)-array with  predicted log probability of the classes   \n",
    "    \"\"\"\n",
    "\n",
    "    # Add your code here: You should load your trained model here \n",
    "    # and write to the corresponding code for making predictions\n",
    "    model = np.load('model.npz')['model'].tolist()\n",
    "    gmm = model[0]\n",
    "    pca = model[1]\n",
    "    length = model[2]\n",
    "    # change to 20 dimensions\n",
    "    xtest_fix = pca.transform(xtest)\n",
    "    pred = np.zeros([xtest.shape[0]],dtype = int)\n",
    "    #save log p(x|y)\n",
    "    loglike = np.zeros([10,xtest.shape[0]])\n",
    "    class_logprob = np.zeros([xtest.shape[0],10])\n",
    "    #using score_samples to get log likelihood of each gmm\n",
    "    for i in range(10):\n",
    "        temp=np.zeros([10,xtest.shape[0]])\n",
    "        for j in range(10):\n",
    "            temp[j]= gmm[i][j].score_samples(xtest_fix)\n",
    "        loglike[i] = np.amax(temp,axis = 0)\n",
    "    #calculate log (p(y|x)∝ p(y)p(x|y)) and make prediction\n",
    "    for i in range(xtest.shape[0]):\n",
    "        pre = 0\n",
    "        maxprob = -999999999\n",
    "        \n",
    "        for j in range(10):\n",
    "            logpyx = np.log((length[j]+.0)/60000) + loglike[j,i]\n",
    "            class_logprob[i,j] = logpyx\n",
    "            \n",
    "            if logpyx>=maxprob:\n",
    "                maxprob = logpyx\n",
    "                pre = j\n",
    "        pred[i] = pre\n",
    "        \n",
    "    #change prediction to one-hot\n",
    "    class_pred = np.eye(10)[pred]    \n",
    "\n",
    "    \n",
    "    return class_pred, class_logprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [20%] Performance \n",
    "You do not need to do anything in this section but you can use it to test the generalisation performance of your code. We will use it the evaluate the performance of your algorithm on a new test test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictive_performance(xdata, ydata, class_pred, class_logprob):\n",
    "    \"\"\"\n",
    "    @param xdata:  (N,D)-array of features \n",
    "    @param ydata:  (N,C)-array of one-hot-encoded true classes\n",
    "    @class_pred: (N,C)-array of one-hot-encoded predicted classes\n",
    "    @class_logprob: (N,C)-array of predicted class log probabilities \n",
    "    \"\"\"\n",
    "    correct = np.zeros(xdata.shape[0])\n",
    "    ltest = np.zeros(xdata.shape[0])\n",
    "    for i, x in enumerate(xdata):\n",
    "        correct[i] = np.all(ydata[i, :] == class_pred[i,:])\n",
    "        ltest[i] = class_logprob[i, np.argmax(ydata[i,:])]\n",
    "    accuracy = correct.mean()\n",
    "    loglike = ltest.mean()\n",
    "    return accuracy, loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pred, class_logprob = make_predictions(xtest)\n",
    "accuracy, loglike = predictive_performance(xtest, ytest, class_pred, class_logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test accuracy=0.976883333333\n",
      "Average test likelihood=-17.039994277\n"
     ]
    }
   ],
   "source": [
    "print 'Average test accuracy=' + str(accuracy)\n",
    "print 'Average test likelihood=' + str(loglike)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:comp9418]",
   "language": "python",
   "name": "conda-env-comp9418-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "179px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
